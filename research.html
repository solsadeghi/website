<html>  
<head>
<TITLE>Sol's Research</TITLE>
</head>

<!--<body BGCOLOR="#FFFFFF" TEXT="#000000">-->
<!--<body BGCOLOR="C0C0C0" TEXT="#000000">-->
<body BGCOLOR="D3D3D3" TEXT="#000000">

<P ALIGN=CENTER>

<TABLE width="750" border="5" bordercolor="483D8B" cellspacing="5" 
cellpadding="5">

<TR><TH>


<IMG SRC = "soheil.jpg" ALT="Soheil" width="396" height="300">

<h1>Sol (Soheil) Sadeghi</h1>
<h3>Download my <A HREF="resume.pdf" target="_blank">Curriculum Vitae</A></h3>


</TH></TR>
<TR><TD>

<div align="justify">

<!--  
<h2>Research</h2>

<br>
<h3>Dissertation</h3>

<ul>
<li> <b>Sliced Desings for Multi-Platform Online Experiments</b><br>
<br>
Multivariate testing is a popular method to improve websites, mobile apps, and email campaigns. A unique aspect of testing in the online space is that it needs to be conducted across multiple platforms such as a desktop and a smartphone. The existing experimental design literature does not offer precise guidance for such a multi-platform context. In this paper, we introduce a multi-platform design framework that allows us to measure the effect of the design factors for each platform and the interaction effect of the design factors with platforms. Substantively, the resulting designs are of great importance for testing digital campaigns across platforms. We illustrate this in an empirical email application to maximize engagement for a digital magazine. We introduce a novel ``sliced effect hierarchy principle'' and develop design criteria to generate factorial designs for multi-platform experiments. To help construct such designs, we prove two theorems that connect the proposed designs to the well-known minimum aberration designs. We find that experimental versions made for one platform should be similar to other platforms. From the standpoint of real world application, such homogeneous sub-designs are cheaper to implement. To assist practitioners, we provide two algorithms to construct the designs that we propose. We also tabulate sliced factorial designs with 16, 32, and 64 runs for four-platform experiments.<br>
<br>


<li><b>Essay 2: Scalable Assessment of Cross Category Promotion Effects Using Machine Learning</b><br>
<br>
For a retailer, like Walmart, each promotion decision is likely to have a direct and an indirect effect.
The former is well studied in marketing mix models. The latter takes two forms (cross category cannibalization
and halo effects) and is under-researched. Indirect effects, are typically studied in highly stylized
setups (e.g. pancake and syrup) or in setups that involve a handful of categories. Parametric models, mostly regression
models with heterogeneity, are usually used to study the indirect effects of promotions on pre-specified items.
However, from a retailer's perspective who cares a great deal about indirect effects, the retailing context involves
a very large number of categories. Therefore, existing models are not scalable to study indirect effects of promotions
for a retailer. In this essay, we focus on the scalable assessment of cross category promotion effects using machine learning.
We propose a framework that is designed to uncover the magnitude and direction of indirect effects. The conceptual framework
relies on behavior based Jaccardian index of similarity to assess indirect effects. Machine learning tools are used to
uncover items that are independent, exhibit cannibalization or halo effects. The conceptual framework is simple
to use, offers usable insights for a retailer and is scalable. The data for our empirical application belongs to Sam's Club
with around 100 categories and 100 subcategories within each category. Sam's Club usually holds promotion campaigns
for almost 20 days every other month. Therefore, there are typically six promotion campaigns and six non-promotion
campaigns in a year. The data for our study is for a six month window starting January 2015 to June 2015 and the
goal is to build a learning algorithm that uses this historical data in order to predict for promotion campaign in
July 2015. The modeling approach reveals insights that a priori would have been hard to hypothesize. <br>

 <br>
<li><b>Essay 3: Optimal Division of Large and Complex Datasets into Homogeneous Batches and Allocation to Different Servers
in order to Perform Parallel Computing</b><br>
<br>
Direct application of most analytic methods to the entire large and complex data is either infeasible or impractical
these days. A new statistical approach to the analysis of large and complex data is to divide it into batches and
allocate each batch to a server for parallel computing. Computationally, each batch is a small dataset. Analytic methods
are applied to each of the batches, and the outputs of each method are combined to form a result for the entire data.
For most applications in industry, the division is random and the recombination is averaging out. The benefit of random
division is that, on average (if we run the process multiple times,) recombination procedure produces a result which is
not very different from the outcome produced by applying the analytic method on the entire data. However, this benefit
is not guaranteed for a single run of this process. In this work, we focus on the division part and propose a new division
methodology that beats random division in terms of estimation and prediction. This methodology can be applied to any analytic
methods and does not depend on the structure of the application. We verify the results by simulations for all popular models
such as linear models, generalized linear models, and nonlinear additive models.<br> 
</ul>
-->

<br>
<h3>Research</h3>
<ul>
<li> Sadeghi, S., Carey, J. (2017). <b> Phase-based Business Cyclic Patterns
in Dynamic Linear Models </b>, submitted to <i> Microsoft Journal of Applied Research </i><br>
<br>
<li> Sadeghi, S., Qian, P.Z.G., and  Arora, N. (2017). <b> Sliced Minimum Aberration Designs for
Four-platform Experiments</b>, to be submitted to <i>Technometrics</i><br>
<br>
<li> Sadeghi, S., Qian, P.Z.G., and  Arora, N. (2016). <b> Sliced Designs for Multi-platform Online Experiments</b>, submitted to <i>Marketing Science</i><br>
<br>
<li> Sadeghi, S., Arora, N., Qian, P.Z.G., Li, J. and Pavlidis, Y. (2015). <b> Scalable Assessment of Cross Category
Promotion Effects Using Machine Learning</b>, working paper<br>
<br>
<li> <b>Sadeghi, S. and Mahlooji, H.</b> (2010). A New Approach in Fitting Linear Regression Models with the Aim of
Improving Accuracy and Power, <i>Journal of Industrial and Systems Engineering (JISE)</i>, Volume 4, Number 2,
pp. 95-113<br>

</ul>

<br>
<h3>Other Projects</h3>

<ul>

<li> <b>2015 - Data Division</b><br>
Optimal division of large and complex datasets into homogeneous batches and allocation to different servers in order to do parallel computing<br>
<br>
<li> <b>2015 - Cannibalization and Halo Effects</b><br>
A probabilistic approach to Cannibalizations and Halo for modeling large and complex Sam's Club data<br>
<br>
<li> <b>2014 - Search Engine Optimization</b><br>
Keyword optimization on a complex dataset from Google AdWords and designing experiments
to fill empty spaces in order to improve conversion profitability<br>
<br>
<li> <b>2014 - Predictive Modeling</b><br>
Predictive response modeling effort in between two waves of mailings to QuickBooks customers
with the aim of improving wave-two response rates and company profits<br>
<br>
<li> <b>2013 - Ranking Algorithms</b><br>
Worked on a dataset from Expedia.com with the aim of learning from consumer behaviors in
order to rank hotels across different queries using machine learning algorithms<br>
</ul>


</div> 

<P ALIGN=right>  

<a href="~sadeghi.html">Back</a> 
   

</TD>           
</TR>


           
</TABLE>

<BR>

</P>

</body>
</html>
